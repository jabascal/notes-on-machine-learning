{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jabascal/notes-on-machine-learning/blob/master/notebook/exploratory_analysis_histograms.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory image analysis - Part 1 : Advanced density plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis and visualization techniques are essential to get insight from the data. Unlock the full power of AI approaches by understanding and focusing on data quality!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis uses descriptive statistics and visualization techniques to provide insights on the data. Descriptive statistics aims at summarizing and analyzing data, and visualization techniques allows highlighting patterns, correlations, trends, outliers and errors in the data, as well as communicating the results. Typical visualization techniques include histograms, scatter plots, box plots, non-linear dimensionality reduction techniques, projection embeddings, dataset sprite plot and interactive version of these plots. In brief, descriptive statistics and visualization techniques are key to gain insights into the data characteristics and distribution.\n",
    "\n",
    "In this article, we look at advanced density visualization techniques, which are useful to understand the data distribution, identify shifts on test data, and improve prediction errors. In specific, we focus on image data, CIFAR10 dataset, and the `joypy` library which yields advanced density plots. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll install the necessary libraries within an environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    !pip install matplotlib==3.8.2 \\\n",
    "        numpy==1.26.3 \\\n",
    "        pillow==10.2.0 \\\n",
    "        pandas==2.2.0 \\\n",
    "        seaborn==0.13.1 \\\n",
    "        joypy==0.2.6 \\\n",
    "        tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), which is a collection 60,000 images of 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. We will use the testset. Images have 32x32 pixels and 3 channels (RGB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be download from the [CIFAR-10 website](https://www.cs.toronto.edu/~kriz/cifar.html) or [Kaggle](https://www.kaggle.com/c/cifar-10/data), but the simplest is to download the data using keras or pytorch. We show how to download the data using keras, which requires to install tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "# Download the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# We retain only the test set\n",
    "images = x_test\n",
    "labels_ids = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define CIFAR-10 labels, as given on the website. We also define different groups for the classes that are expected to present similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels and CIFAR-10 classes\n",
    "channels = ['r', 'g', 'b']\n",
    "cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] \n",
    "cifar10_labels_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "#cifar10_labels_idx = os.listdir(data_dir)\n",
    "\n",
    "# Labels names\n",
    "labels_names = [cifar10_labels[label_id[0]] for label_id in labels_ids]\n",
    "\n",
    "# Define groups with similar classes\n",
    "cifar10_groups = {'transport': ['airplane', 'ship', 'automobile', 'truck'],\n",
    "                      'pet': ['cat', 'dog'], \n",
    "                       'wild': ['deer', 'horse', 'frog', 'bird']}\n",
    "\n",
    "# Name for dataset (for saving results)\n",
    "result_name = 'cifar10'\n",
    "\n",
    "# Path for results\n",
    "result_dir = '../Results/cifar10/data_anal/'    \n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the data, we display few random images and then a sprite of the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_grid_images_labels(images, labels, dim_resize=None, num_subplots=(3, 3), \n",
    "                      figsize = (6, 6), path_file=None):\n",
    "    \"\"\"\n",
    "    Load and display a grid of images from the specified list of image files.    \n",
    "    \"\"\"\n",
    "    # Create a grid to display the images\n",
    "    fig, axes = plt.subplots(num_subplots[0], num_subplots[1], figsize=figsize)\n",
    "    axes = axes.flatten()  # Flatten the axes array\n",
    "    # Load and display the selected images on the grid\n",
    "    for i, (img, label) in enumerate(zip(images, labels)):        \n",
    "        #ax = axes[i // num_subplots[0], i % num_subplots[1]]\n",
    "        ax = axes[i]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')\n",
    "    if path_file is not None:\n",
    "        fig.savefig(path_file)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "num_selected = 16\n",
    "images_selected = [images[i] for i in range(num_selected)]\n",
    "labels_selected = [cifar10_labels[labels_ids[i][0]] for i in range(num_selected)]\n",
    "file_save = os.path.join(result_dir, f'{result_name}_img.png')\n",
    "display_grid_images_labels(images_selected, labels_selected, \n",
    "                           path_file=file_save, figsize=(5,6), num_subplots=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To easily inspect an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1000\n",
    "print(f'Label: {cifar10_labels[labels_ids[ind][0]]}')\n",
    "Image.fromarray(images[ind]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common to create a sprite plot of the dataset, which is a single image that contains all or a subset of the images in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_sprite(data, invert_colors=False):\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    if invert_colors:\n",
    "       data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data, n\n",
    "\n",
    "# Subsample the dataset\n",
    "num_selected = 25*25\n",
    "images_2d = np.array(images[:num_selected,:,:,:]).reshape(-1, 32, 32, 3)\n",
    "\n",
    "# Create the sprite image\n",
    "sprite, n = images_to_sprite(images_2d)\n",
    "sprite_path = os.path.join(result_dir, f'{result_name}_sprite.png')\n",
    "Image.fromarray(sprite).save(sprite_path)\n",
    "#Image.fromarray(sprite).show()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.imshow(sprite)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary statistics provides a quantitative summary of the data with a few numbers. It is fast way to get a general idea of the data. We use pandas to create a dataframe of the dataset. Then, we group the data by `class` and use the `describe` method to provide a summary of the central tendency, dispersion and shape of the dataset. \n",
    "\n",
    "For large image datasets, we would need to subsample the dataset/images or preprocess the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_class(images, labels_ids, labels_names, channels, class_name='class'):\n",
    "    \"\"\"\n",
    "    Given images array, labels ids array, labels names list and channels list, \n",
    "    create a dataframe for each class and then concantenate all dataframes.\n",
    "    \"\"\"\n",
    "    for label_id in range(len(labels_names)):\n",
    "        # Combine all pixels for same group\n",
    "        images_subgroup = images[labels_ids.flatten() == label_id]\n",
    "        images_subgroup = images_subgroup.reshape(-1, 3)\n",
    "        \n",
    "        # Create dataframe\n",
    "        images_subgroup_df = pd.DataFrame(images_subgroup, columns=channels)\n",
    "        images_subgroup_df[class_name] = labels_names[label_id]\n",
    "        if label_id == 0:\n",
    "            images_df = images_subgroup_df        \n",
    "        else:\n",
    "            images_df = pd.concat([images_df, images_subgroup_df], axis=0, ignore_index=True)\n",
    "\n",
    "    return images_df\n",
    "\n",
    "# Create a dataframe with all images\n",
    "num_selected = 500\n",
    "images_df = create_df_class(images[:num_selected,:,:,:], labels_ids[:num_selected], cifar10_labels, channels)\n",
    "# print(images_df)\n",
    "\n",
    "# Group by class\n",
    "images_df_group = images_df.groupby('class')\n",
    "\n",
    "# Display stats\n",
    "stats = images_df_group.describe()\n",
    "stats = stats.transpose()\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization with common plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common plots that provide a general description of the data are histograms, scatter plots, box plots, and correlation plots. Pandas and seaborn are common libraries for these plots. Here, we focus on histograms. We will start by showing that it is quite tricky to get useful insight with two examples of these plots. Then, we will look at more advance or dedicated tools for displaying densities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograms** provide a visual representation of the distribution of the data, as they represent the frequency of the values in the dataset. They hightlight the shape and skewness of the distribution and can help to indetify outliers. The bins are the intervals of the values. \n",
    "\n",
    "As a first example, we use *pandas* `hist` method to plot the histogram for one class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select class bird and plot histogram using pandas\n",
    "class_selected = 'bird'\n",
    "images_df_class = images_df[images_df['class'] == class_selected]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(7, 4))\n",
    "for i, channel in enumerate(channels):\n",
    "    images_df_class.hist(column=channel, ax=axes[i], bins=20, alpha=0.5)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other libraries such as *seaborn* yield higher quality plots. [Seaborn](https://seaborn.pydata.org/index.html) is a well known Python library based on *matplotlib* that provides a high-level interface for displaying statistical graphics. \n",
    "\n",
    "A useful plot to start the exploratory analysis is the **pairplot**, also known as scatterplot matrix. It creates a grid of scatter plots, where each variable in the dataset is plotted against each other. The diagonal plots are histograms of the corresponding variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.pairplot(images_df.sample(10000), hue='class' )\n",
    "fig.savefig(os.path.join(result_dir, f'{result_name}_pairplot.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cannot see much? Well, I can't! \n",
    "- Histograms are cluttered!\n",
    "\n",
    "- Scatter plots do not provide much information either on this case! Scatter plots are usefull to find relations between variables. In this case variables are RGB channels. \n",
    "\n",
    "Even though the plots are quite nice, they do not provide great inside for image data. We need another tool to come to the rescue for comparing histograms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced histogram plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An usefull libray to plot histograms is [joypy](https://github.com/sessions/two-factor/mobile?auto=true). Joyplot is also a matplotlib- and pandas-based library for partially overlapping plots. \n",
    "\n",
    "In order to get further insight into the data, we separte plots by subclasses for clarity and for better identifying similar distributions. It may take a minute to estimate the density for each class, depending on the number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joypy\n",
    "\n",
    "# Plot per subclass\n",
    "for subclass in cifar10_groups.keys():\n",
    "    images_subclass = images_df[images_df['class'].isin(cifar10_groups[subclass])]\n",
    "    fig, axes = joypy.joyplot(images_subclass, \n",
    "                              legend=True,\n",
    "                              color=['r', 'g', 'b'],\n",
    "                              fade=True,\n",
    "                              by='class', \n",
    "                              figsize=(6,3),)                       \n",
    "    fig.savefig(os.path.join(result_dir, f'{result_name}_jp_{subclass}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice the similarities between classes? Cat and dog have very similar distributions, as well as automobile and truck, and deer and horse. We also notice that ship and bird are skewed to the left (left-tailed) because of the blue colors of sea and sky, respectively. These distributions opposed to the rest of the distributions and to the general distribution of the dataset, which are mostly right-tailed distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skewness and kurtosis are two important measures of the shape of the distribution. Skewness refers to symmetry of distribution, while kurtosis refers to the tail of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = images_df_group.skew()\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare to the distribution of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot histogram of all dataset\n",
    "fig, axes = joypy.joyplot(images_df, \n",
    "                          legend=True,\n",
    "                          color=['r', 'g', 'b'], \n",
    "                          figsize=(6,3))\n",
    "fig.savefig(os.path.join(result_dir, f'{result_name}_jp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous metrics are global measures. We have already explored those across subclasses. We can also display histograms of individual images; for instance, the worst performing cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we select few images for few subclasses. We can see the large variability across image samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for a new image\n",
    "# cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] \n",
    "# cifar10_labels_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "num_images_new = 5\n",
    "images_selected_classes = []\n",
    "for class_id_new in [0, 5, 3]:\n",
    "    class_id_new = int(class_id_new)\n",
    "    images_selected = []\n",
    "    labels_selected = []\n",
    "    # Take few random images from the selected class\n",
    "    labels_selected_idx = np.where(labels_ids == class_id_new)[0]    \n",
    "    labels_selected_idx = np.random.choice(labels_selected_idx, num_images_new)\n",
    "    for label_selected_idx in labels_selected_idx:\n",
    "        image_new = images[label_selected_idx,:,:,:]\n",
    "        images_selected.append(image_new)\n",
    "        labels_selected.append(cifar10_labels[class_id_new] + f'_{label_selected_idx}')\n",
    "    images_selected = np.array(images_selected)\n",
    "    labels_selected = np.array(labels_selected)\n",
    "    images_selected_classes.append(images_selected)\n",
    "\n",
    "    # Create a dataframe with selectd images\n",
    "    images_selected_df = create_df_class(images_selected, np.array(range(len(labels_selected))), labels_selected, channels)\n",
    "    \n",
    "    fig, axes = joypy.joyplot(images_selected_df, \n",
    "                            legend=True,\n",
    "                            color=['r', 'g', 'b'], \n",
    "                            fade=True, \n",
    "                            by='class', \n",
    "                            figsize=(5,3))\n",
    "    fig.savefig(os.path.join(result_dir, f'{result_name}_jp_new_{cifar10_labels[class_id_new]}.png'))\n",
    "images_selected_classes = np.array(images_selected_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize the selected images using a sprite plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprites of selected image\n",
    "images_2d = np.array(images_selected_classes).reshape(-1, 32, 32, 3)\n",
    "sprite, n = images_to_sprite(images_2d)\n",
    "sprite_path = os.path.join(result_dir, f'{result_name}_selected_sprite.png')\n",
    "Image.fromarray(sprite).save(sprite_path)\n",
    "#Image.fromarray(sprite).show()\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.imshow(sprite)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several libraries provide interactive plots, such as [plotly](https://plotly.com/python), [bokeh](https://docs.bokeh.org/en/latest/index.html), [Vega-Altair](https://altair-viz.github.io), and [pygal](http://www.pygal.org/en/stable), among others. This would be subject of another notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Histograms can provide first insights on the data, specially for applications for which different classes can have different range of values. Histograms are also key in machine learning, as all taks can be seen as explicitly or implicitly learning the distribution of the data. In addition, this analysis can be also usefull for error analysis; for instance, by looking at cases that are not well classified.\n",
    " \n",
    " In this dataset, we consider the channels as variables and the pixels as observations. This choice is an example for illustration purposes, and other more meaningful variables can be defined depending on the application. \n",
    "\n",
    " A word of caution is raised when over-relying on summary statistics, providing global metrics [Alabi 2023]. However, they are a great starting point to get insight and they can be used to allert of potential shifts in the data. \n",
    "\n",
    " In this notebook, we have introduced descriptive statistics and data exploration and have focussed on histograms. Other great techniques for image data are projection embeddings and non-linear dimensionality reduction techniques, which allow to visualize all data points in a 2D or 3D space. We will look at these techniques in future notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alex Krizhevsky, Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009. [Link](https://api.semanticscholar.org/CorpusID:18268744)\n",
    "\n",
    "[Alabi 2023] Olubunmi Alabi and Tosin Bukola. Introduction to Descriptive statistics, Recent Advances in Biostatistics, 2023. [Link](https://www.intechopen.com/online-first/1141192)\n",
    "\n",
    "[Kaur 2018] P Kaur et al. Descriptive statistics. International Journal of Academic Medicine 4(1):p 60-63, Janâ€“Apr, 2018.\n",
    "\n",
    "[Nick 2007] T Nick. Topics in Biostatistics. Methods in Molecular Biology. Chapter 3: Descriptive statistics, 2007. [Link](https://www.researchgate.net/profile/Douglas-Case/publication/5402496_Power_and_Sample_Size/links/00b49539f39fea3b24000000/Power-and-Sample-Size.pdf?_sg%5B0%5D=started_experiment_milestone&origin=journalDetail#page=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
