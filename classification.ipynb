{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classification.ipynb","provenance":[],"authorship_tag":"ABX9TyMfyhdHJDkb5XQ77aNbZxWP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1y_-miW8qZcU"},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{"id":"cIDkPwuAslp8"},"source":["In this chapter, we are interested in predicting qualitative responses $G(x)$, given the inputs $x$. The predictor $G(x)$ takes values in a discrete set $C$, comprised of $K$ classes, labelled as $1, 2, \\ldots, K$, such that $G(x)\\in C$. We would like to estimate the probability of the input to belong to a given class.\n"]},{"cell_type":"markdown","metadata":{"id":"qquQH33LxpMb"},"source":["## Linear regression"]},{"cell_type":"markdown","metadata":{"id":"cmOJpH0Cx6HD"},"source":["One could use linear regression to model the conditional probability \n","$$\n","Pr(G=k|X=x)=\\beta_0+\\beta_1x,\n","$$\n","and assign the class with highest probability. For a binary response, linear regression is equivalent as linear discriminant analysis, which assumes response densities for each class to be Gaussian. The problem with this approach is that the output of the regression can be negative or larger than one. "]},{"cell_type":"markdown","metadata":{"id":"G6ws8HQczDcD"},"source":["## Logistic regression"]},{"cell_type":"markdown","metadata":{"id":"2uG4uXg3zINc"},"source":["Instead of modelling the response, logistic regression model probability of the input to belong to each category. For a binary problem, with classes $G=\\{1,2\\}$, the posterior probabilities \n","$$\n","Pr(G=1|X=x)=\\frac{\\exp{(\\beta_0+\\beta_1x)}}{1+\\exp{(\\beta_0+\\beta_1x)}},\n","$$\n","$$\n","Pr(G=2|X=x)=\\frac{1}{1+\\exp{(\\beta_0+\\beta_1x)}}.\n","$$"]}]}